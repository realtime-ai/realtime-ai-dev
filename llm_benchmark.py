import argparse
import asyncio
import base64
import dataclasses
import json
import mimetypes
import os
import re
import time
import urllib
from datetime import datetime
from pathlib import Path
from typing import Any, AsyncGenerator, Callable, Dict, List, Optional, Tuple
import requests
import sseclient
import pandas as pd

import dataclasses_json


from dotenv import load_dotenv
load_dotenv()

print('ENV:', os.getenv("SILICON_API_KEY"))

SILICON_API_KEY = os.getenv("SILICON_API_KEY")  # ç¡…åŸºæµåŠ¨
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")  # é˜¿é‡Œäº‘
ARK_API_KEY = os.getenv("ARK_API_KEY")  # ç«å±±å¼•æ“


SILICON_MODELS = [
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen3-30B-A3B",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen3-32B",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen3-14B",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen3-8B",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen3-235B-A22B",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "Qwen/Qwen2.5-VL-32B-Instruct",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },
    {
        "provider": "ç¡…åŸºæµåŠ¨",
        "model": "deepseek-ai/DeepSeek-V3",
        "url": "https://api.siliconflow.cn/v1/chat/completions",
        "api_key": os.getenv("SILICON_API_KEY"),
    },

]

DASHSCOPE_MODELS = [
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-235b-a22b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-30b-a3b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-32b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-14b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-8b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-4b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen3-1.7b",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen-turbo-2025-04-28",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    },
    {
        "provider": "é˜¿é‡Œäº‘",
        "model": "qwen-plus-2025-04-28",
        "url": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
        "api_key": os.getenv("DASHSCOPE_API_KEY"),
    }

]


ARK_MODELS = [
    {
        "provider": "ç«å±±å¼•æ“",
        "model": "doubao-seed-1.6-250615",
        "url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
        "api_key": os.getenv("ARK_API_KEY"),
    },
    {
        "provider": "ç«å±±å¼•æ“",
        "model": "doubao-seed-1.6-flash-250615",
        "url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
        "api_key": os.getenv("ARK_API_KEY"),
    },
    {
        "provider": "ç«å±±å¼•æ“",
        "model": "deepseek-v3-250324",
        "url": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
        "api_key": os.getenv("ARK_API_KEY"),
    }
]


DEEPSEEK_MODELS = [
    {
        "provider": "DeepSeek",
        "model": "deepseek-chat",
        "url": "https://api.deepseek.com/v1/chat/completions",
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
    },
]


# æµ‹è¯•åœ°ç‚¹é…ç½® - ç»Ÿä¸€ä¸ºåŒ—äº¬åœ°åŒº
CURRENT_LOCATION = "åŒ—äº¬"

# åˆå¹¶æ‰€æœ‰æ¨¡å‹
LLM_MODELS = SILICON_MODELS + DASHSCOPE_MODELS + ARK_MODELS + DEEPSEEK_MODELS


@dataclasses.dataclass
class Metrics(dataclasses_json.DataClassJsonMixin):
    provider: str
    model: str
    location: str
    ttft: Optional[float] = None  # Time to first token (ms)
    tps: Optional[float] = None   # Tokens per second
    input_tokens: Optional[int] = None
    output_tokens: Optional[int] = None
    total_tokens: Optional[int] = None
    total_time: Optional[float] = None  # Total time (ms)
    output: Optional[str] = None
    error: Optional[str] = None
    status: str = "pending"  # pending, success, error


class LLMBenchmark:
    def __init__(self, provider: str, url: str, api_key: str, model: str, input_text: str, location: str):
        self.provider = provider
        self.url = url
        self.api_key = api_key
        self.model = model
        self.input_text = input_text
        self.location = location
        self.metric: Metrics = Metrics(
            provider=provider, model=model, location=location)

    async def run(self) -> Metrics:
        start_time = time.time()
        first_token_time = None
        total_tokens = 0
        input_tokens = 0
        output_tokens = 0
        output_content = ""

        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "Accept": "application/json",
            }
            data = {
                "model": self.model,
                "messages": [{"role": "user", "content": self.input_text}],
                "stream": True,
                "max_tokens": 1000,
                "stream_options": {
                    "include_usage": True,
                }
            }

            if self.provider == "ç«å±±å¼•æ“":
                data["thinking"] = {
                    "type": "disabled"
                }

            if self.provider == "é˜¿é‡Œäº‘":
                data["enable_thinking"] = False

            data = self.disable_thinking(data)

            response = requests.post(
                self.url, headers=headers, stream=True, json=data, timeout=30)

            if response.status_code != 200:
                raise Exception(
                    f"APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")

            client = sseclient.SSEClient(response)

            for event in client.events():
                if event.data != "[DONE]":
                    try:
                        chunk = json.loads(event.data)
                        if chunk.get('choices'):
                            delta = chunk['choices'][0]['delta']
                            if 'content' in delta and delta['content']:
                                if first_token_time is None:
                                    first_token_time = time.time()
                                output_content += delta['content']

                        usage = chunk.get("usage")
                        if usage:
                            input_tokens = usage.get("prompt_tokens", 0)
                            output_tokens = usage.get("completion_tokens", 0)
                            total_tokens = usage.get("total_tokens", 0)
                    except json.JSONDecodeError:
                        print(f"æ— æ³•è§£æäº‹ä»¶æ•°æ®: {event.data}")

            end_time = time.time()

            if first_token_time is None:
                raise Exception("æœªæ”¶åˆ°ä»»ä½•token")

            first_token_latency = (
                first_token_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            total_duration = (end_time - start_time) * 1000

            self.metric.total_time = total_duration
            self.metric.input_tokens = input_tokens
            self.metric.output_tokens = output_tokens
            self.metric.total_tokens = total_tokens
            self.metric.output = output_content
            self.metric.ttft = first_token_latency

            # è®¡ç®—TPS (tokens per second)
            if total_duration > 0 and output_tokens > 0:
                self.metric.tps = (output_tokens / (total_duration / 1000))
            else:
                self.metric.tps = 0

            self.metric.status = "success"

        except Exception as e:
            self.metric.error = str(e)
            self.metric.status = "error"
            print(f"æ¨¡å‹ {self.model} æµ‹è¯•å¤±è´¥: {e}")

        return self.metric

    def disable_thinking(self, data: dict):
        if self.provider == "ç«å±±å¼•æ“":
            data["thinking"] = {
                "type": "disabled"
            }
        elif self.provider == "é˜¿é‡Œäº‘":
            data["enable_thinking"] = False
        elif self.provider == "ç¡…åŸºæµåŠ¨":
            data["enable_thinking"] = False
        elif self.provider == "DeepSeek":
            data["enable_thinking"] = False
        return data


def generate_table(metrics: List[Metrics]) -> str:
    """ç”Ÿæˆè¯„æµ‹ç»“æœè¡¨æ ¼"""
    # å‡†å¤‡è¡¨æ ¼æ•°æ®
    table_data = []
    for metric in metrics:
        row = {
            "æä¾›å•†": metric.provider,
            "æ¨¡å‹": metric.model,
            "çŠ¶æ€": metric.status,
            "é¦–Tokenå»¶è¿Ÿ(ms)": f"{metric.ttft:.1f}" if metric.ttft else "N/A",
            "ç”Ÿæˆé€Ÿåº¦(tokens/s)": f"{metric.tps:.1f}" if metric.tps else "N/A",
            "è¾“å…¥Tokenæ•°": metric.input_tokens or "N/A",
            "è¾“å‡ºTokenæ•°": metric.output_tokens or "N/A",
            "æ€»Tokenæ•°": metric.total_tokens or "N/A",
            "æ€»è€—æ—¶(ms)": f"{metric.total_time:.1f}" if metric.total_time else "N/A",
            "é”™è¯¯ä¿¡æ¯": metric.error or "N/A"
        }
        table_data.append(row)

    # ä½¿ç”¨pandasç”Ÿæˆè¡¨æ ¼
    df = pd.DataFrame(table_data)

    # ç”Ÿæˆmarkdownè¡¨æ ¼
    markdown_table = df.to_markdown(index=False, tablefmt="grid")

    # ç”ŸæˆHTMLè¡¨æ ¼
    html_table = df.to_html(
        index=False, classes="table table-striped table-bordered")

    return markdown_table, html_table


def generate_summary_stats(metrics: List[Metrics]) -> str:
    """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
    successful_metrics = [m for m in metrics if m.status == "success"]

    if not successful_metrics:
        return "æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ"

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    ttft_values = [m.ttft for m in successful_metrics if m.ttft]
    tps_values = [m.tps for m in successful_metrics if m.tps]

    summary = f"""
## è¯„æµ‹ç»Ÿè®¡æ‘˜è¦

### æ€»ä½“ç»Ÿè®¡
- æ€»æµ‹è¯•æ¨¡å‹æ•°: {len(metrics)}
- æˆåŠŸæµ‹è¯•æ•°: {len(successful_metrics)}
- å¤±è´¥æµ‹è¯•æ•°: {len(metrics) - len(successful_metrics)}

### æ€§èƒ½æŒ‡æ ‡ç»Ÿè®¡
"""

    if ttft_values:
        summary += f"""
**é¦–Tokenå»¶è¿Ÿ (TTFT)**
- å¹³å‡å€¼: {sum(ttft_values)/len(ttft_values):.1f} ms
- æœ€å°å€¼: {min(ttft_values):.1f} ms
- æœ€å¤§å€¼: {max(ttft_values):.1f} ms
"""

    if tps_values:
        summary += f"""
**ç”Ÿæˆé€Ÿåº¦ (TPS)**
- å¹³å‡å€¼: {sum(tps_values)/len(tps_values):.1f} tokens/s
- æœ€å°å€¼: {min(tps_values):.1f} tokens/s
- æœ€å¤§å€¼: {max(tps_values):.1f} tokens/s
"""

    return summary


async def run_benchmark() -> List[Metrics]:
    metrics = []
    print(f"å¼€å§‹è¯„æµ‹ {len(LLM_MODELS)} ä¸ªæ¨¡å‹ï¼Œæµ‹è¯•åœ°åŒº: {CURRENT_LOCATION} (æ¯ä¸ªæ¨¡å‹æµ‹è¯•2æ¬¡å–å¹³å‡)")

    for i, model in enumerate(LLM_MODELS, 1):
        print(
            f"[{i}/{len(LLM_MODELS)}] æµ‹è¯•æ¨¡å‹: {model['provider']} - {model['model']} (åœ°åŒº: {CURRENT_LOCATION})")

        # æ¯ä¸ªæ¨¡å‹è¿è¡Œ2æ¬¡
        run_metrics = []
        for run_num in range(2):
            print(f"  ç¬¬ {run_num + 1} æ¬¡æµ‹è¯•...")

            benchmark = LLMBenchmark(
                provider=model["provider"],
                url=model["url"],
                api_key=model["api_key"],
                model=model["model"],
                input_text="ç»™æˆ‘èƒŒä¸€é¦–æç™½çš„è¯—è¯ï¼ŒèƒŒä¸¤æ¬¡",
                location=CURRENT_LOCATION
            )
            metric = await benchmark.run()
            run_metrics.append(metric)

            # æ‰“å°å½“å‰æµ‹è¯•ç»“æœ
            if metric.status == "success":
                print(
                    f"    âœ“ æˆåŠŸ - TTFT: {metric.ttft:.1f}ms, TPS: {metric.tps:.1f}")
            else:
                print(f"    âœ— å¤±è´¥ - {metric.error}")

            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            await asyncio.sleep(1.0)

        # è®¡ç®—å¹³å‡å€¼
        successful_runs = [m for m in run_metrics if m.status == "success"]

        if successful_runs:
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_metric = Metrics(
                provider=model["provider"],
                model=model["model"],
                location=CURRENT_LOCATION,
                status="success"
            )

            # è®¡ç®—å¹³å‡å€¼
            avg_metric.ttft = sum(
                m.ttft for m in successful_runs if m.ttft) / len(successful_runs)
            avg_metric.tps = sum(
                m.tps for m in successful_runs if m.tps) / len(successful_runs)
            avg_metric.total_time = sum(
                m.total_time for m in successful_runs if m.total_time) / len(successful_runs)
            avg_metric.input_tokens = round(sum(
                m.input_tokens for m in successful_runs if m.input_tokens) / len(successful_runs))
            avg_metric.output_tokens = round(sum(
                m.output_tokens for m in successful_runs if m.output_tokens) / len(successful_runs))
            avg_metric.total_tokens = round(sum(
                m.total_tokens for m in successful_runs if m.total_tokens) / len(successful_runs))

            # åˆå¹¶è¾“å‡ºå†…å®¹ï¼ˆä½¿ç”¨ç¬¬ä¸€æ¬¡æˆåŠŸçš„è¾“å‡ºï¼‰
            avg_metric.output = successful_runs[0].output

            metrics.append(avg_metric)
            print(
                f"  ğŸ“Š å¹³å‡ç»“æœ - TTFT: {avg_metric.ttft:.1f}ms, TPS: {avg_metric.tps:.1f} (åŸºäº {len(successful_runs)} æ¬¡æˆåŠŸæµ‹è¯•)")
        else:
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡çš„é”™è¯¯ç»“æœ
            failed_metric = run_metrics[-1]
            metrics.append(failed_metric)
            print(f"  âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥")

        print()  # ç©ºè¡Œåˆ†éš”

    return metrics


def generate_gradio_leaderboard_data(metrics: List[Metrics], location: str) -> Dict:
    """
    ç”ŸæˆæŒ‡å®šåœ°åŒºçš„Gradio Leaderboardç»„ä»¶æ‰€éœ€çš„JSONæ•°æ®æ ¼å¼
    """
    # è¿‡æ»¤å‡ºæŒ‡å®šåœ°åŒºå’ŒæˆåŠŸçš„æµ‹è¯•ç»“æœ
    successful_metrics = [m for m in metrics if m.status ==
                          "success" and m.location == location]

    if not successful_metrics:
        return {"data": [], "columns": []}

    # å‡†å¤‡æ•°æ®è¡Œ
    data_rows = []
    for metric in successful_metrics:
        ttft_val = round(metric.ttft, 1) if metric.ttft else 0
        tps_val = round(metric.tps, 1) if metric.tps else 0

        # æ·»åŠ æ€§èƒ½ç­‰çº§
        ttft_performance = 'ğŸŸ¢ ä¼˜ç§€' if ttft_val < 200 else (
            'ğŸŸ¡ è‰¯å¥½' if ttft_val < 400 else 'ğŸ”´ ä¸€èˆ¬')
        tps_performance = 'ğŸŸ¢ ä¼˜ç§€' if tps_val > 40 else (
            'ğŸŸ¡ è‰¯å¥½' if tps_val > 20 else 'ğŸ”´ ä¸€èˆ¬')

        row = {
            "model": metric.model,
            "provider": metric.provider,
            "location": metric.location,
            "ttft": ttft_val,
            "ttft_performance": ttft_performance,
            "tps": tps_val,
            "tps_performance": tps_performance,
            "total_time": round(metric.total_time, 1) if metric.total_time else 0,
            "output_tokens": metric.output_tokens or 0,
            "status": metric.status
        }
        data_rows.append(row)

    # æŒ‰é¦–Tokenå»¶è¿Ÿæ’åºï¼ˆè¶Šä½è¶Šå¥½ï¼‰
    data_rows.sort(key=lambda x: x["ttft"])

    # å®šä¹‰åˆ—é…ç½®
    columns = [
        {"name": "model", "label": "æ¨¡å‹", "type": "str"},
        {"name": "provider", "label": "æä¾›å•†", "type": "str"},
        {"name": "location", "label": "æµ‹è¯•åœ°ç‚¹", "type": "str"},
        {"name": "ttft", "label": "é¦–Tokenå»¶è¿Ÿ(ms)", "type": "number"},
        {"name": "ttft_performance", "label": "å»¶è¿Ÿç­‰çº§", "type": "str"},
        {"name": "tps", "label": "ç”Ÿæˆé€Ÿåº¦(tokens/s)", "type": "number"},
        {"name": "tps_performance", "label": "é€Ÿåº¦ç­‰çº§", "type": "str"},
        {"name": "total_time", "label": "æ€»è€—æ—¶(ms)", "type": "number"},
        {"name": "output_tokens", "label": "è¾“å‡ºTokenæ•°", "type": "number"},
        {"name": "status", "label": "çŠ¶æ€", "type": "str"}
    ]

    return {
        "data": data_rows,
        "columns": columns
    }


def save_leaderboard_data_by_location(metrics: List[Metrics], date_str: str):
    """
    ä¿å­˜å½“å‰æµ‹è¯•åœ°åŒºçš„leaderboardæ•°æ®åˆ°dataç›®å½•
    """
    # ç¡®ä¿dataç›®å½•å­˜åœ¨
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆå½“å‰åœ°åŒºçš„æ•°æ®
    location_data = generate_gradio_leaderboard_data(metrics, CURRENT_LOCATION)

    # æ–‡ä»¶åæ ¼å¼: leaderboard_{location}_{date}.json
    filename = f"leaderboard_{CURRENT_LOCATION}_{date_str}.json"
    filepath = data_dir / filename

    # ä¿å­˜æ•°æ®
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(location_data, f, ensure_ascii=False, indent=2)

    print(f"å·²ä¿å­˜ {CURRENT_LOCATION} åœ°åŒºæ•°æ®åˆ°: {filepath}")


if __name__ == "__main__":
    print(f"å¼€å§‹LLMæ¨¡å‹æ€§èƒ½è¯„æµ‹... (æµ‹è¯•åœ°åŒº: {CURRENT_LOCATION})")

    metrics = asyncio.run(run_benchmark())

    # ç”Ÿæˆè¡¨æ ¼
    markdown_table, html_table = generate_table(metrics)

    # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
    summary = generate_summary_stats(metrics)

    # è·å–å½“å‰æ—¥æœŸ
    current_date = datetime.now().strftime("%Y-%m-%d")

    # ä¿å­˜å½“å‰åœ°åŒºçš„Leaderboardæ•°æ®
    save_leaderboard_data_by_location(metrics, current_date)

    print("\n" + "="*50)
    print("è¯„æµ‹å®Œæˆï¼")
    print("="*50)
    print(summary)
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° data/ ç›®å½•ï¼Œåœ°åŒº: {CURRENT_LOCATION}ï¼Œæ—¥æœŸ: {current_date}")
    print("\nè¯¦ç»†ç»“æœè¡¨æ ¼:")
    print(markdown_table)
